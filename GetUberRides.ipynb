{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c0db08-e256-44fa-abb3-e4b232bc5312",
   "metadata": {},
   "source": [
    "# Get Uber Ride Data\n",
    "\n",
    "As a full-time Uber driver, I'm interested in performing analysis on my past rides so I can make informed choices about driving in the future and how to optimize for higher earnings. However, when I log in to the [Uber Drivers](https://drivers.uber.com/earnings/activities) page, I can only view my past rides a week at a time, and that weekly view is frustratingly paginated and lacks relevant details. Being a programmer, I naturally thought of downloading the data through an API. As of August 24, 2024 access to the [Uber Drivers API](https://developer.uber.com/docs/drivers/introduction) is \"limited\" and there's a vague message on their info page about applying for access. So that's not a solution for my personal data needs. \n",
    "\n",
    "**Caveat**: This is likely against the Uber Drivers TOS and I'm engaging with this at my own risk of potentially haveing my account limited/banned, but I really want to get this data and I'm requesting in a reasonable manner. **Proceed at your own risk.** \n",
    "\n",
    "## Reverse Engineering the Uber Drivers page\n",
    "\n",
    "By going into the Google Chrome Developer Console Network tab when loading the Uber Drivers page, I can see that the weekly paginated rides data is initially retrieved through an HTTP POST request to `https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en` with the request payload:\n",
    "\n",
    "```\n",
    "{\"startDateIso\":\"2024-05-13\",\"endDateIso\":\"2024-05-20\",\"paginationOption\":{}}\n",
    "```\n",
    "\n",
    "This retrieves a JSON object including my rides data that's far richer than what's actually displayed on the page. Jackpot! \n",
    "\n",
    "If there are more pages of data, then the JSON object (I'll refer to as `data`) has `data['data']['pagination']['hasMoreData']` set to `True`. There is then a pagination cursor value available in `data['data']['pagination']['nextCursor']`, and the next page of data can be requested with a similar HTTP POST request to `https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en` with the request payload:\n",
    "\n",
    "```\n",
    "{\"startDateIso\":\"2024-05-13\",\"endDateIso\":\"2024-05-20\",\"paginationOption\":{\"cursor\": data['data']['pagination']['nextCursor']}}\n",
    "```\n",
    "\n",
    "Repeating this request until `data['data']['pagination']['hasMoreData']` is `False` will retrieve all data for that time period. \n",
    "\n",
    "Performing this entire series of requests for all weekly date ranges from the date I started driving Uber (2023-01-09) to now will get me all of my ride data. \n",
    "\n",
    "Importantly, this is all occurring inside an authenticated HTTPS session. In my initial discovery and testing, I used Postman to perform the requests. Through the Network tab in the Google Chrome Developer Console, I right-clicked the POST request, chose `Copy > Copy as cURL`, and then imported that into Postman using `File > Import...`. \n",
    "\n",
    "After confirming it worked, I migrated to Python to request everything programmatically. To generate starter code for Python requests, in Postman on this particular request I chose the `Code` option in the pane on the right side of the window, then chose \"Python - Requests\" from the drop-down menu. This includes the full authentication tokens in plaintext on the `cookies` key of the headers dictionary. \n",
    "\n",
    "With all of the data downloaded, I extract the rides data specifically and save this to a local JSON file so I don't have to re-request the data. I then perform some data cleaning, parsing, and enrichment to ultimately produce CSV files that I can easily analyze with other programs and import into a spreadsheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f02ccdf3-6a47-4341-9f7c-52101465cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import re\n",
    "import browsercookie\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d37fc9-757c-43ac-bd35-85001a9c6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UberDriver:\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "          'accept': '*/*',\n",
    "          'accept-language': 'en-US,en;q=0.9',\n",
    "          'content-type': 'application/json',\n",
    "            # Take the 'cookie' value out of the generated code from Postman\n",
    "            # 'cookie': '',\n",
    "          'origin': 'https://drivers.uber.com',\n",
    "          'priority': 'u=1, i',\n",
    "          'referer': 'https://drivers.uber.com/earnings/activities',\n",
    "          'sec-ch-ua': '\"Not)A;Brand\";v=\"99\", \"Google Chrome\";v=\"127\", \"Chromium\";v=\"127\"',\n",
    "          'sec-ch-ua-mobile': '?0',\n",
    "          'sec-ch-ua-platform': '\"macOS\"',\n",
    "          'sec-fetch-dest': 'empty',\n",
    "          'sec-fetch-mode': 'cors',\n",
    "          'sec-fetch-site': 'same-origin',\n",
    "          'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',\n",
    "          'x-csrf-token': 'x',\n",
    "          'x-uber-earnings-seed': '84fe34091ffc6c333a1a8a4f93ac6d21'\n",
    "        }\n",
    "    \n",
    "    def get_rides(self, start_date_iso, end_date_iso):        \n",
    "        url = \"https://drivers.uber.com/earnings/api/getWebActivityFeed?localeCode=en\"\n",
    "    \n",
    "        payload = json.dumps({\n",
    "          \"startDateIso\": start_date_iso,\n",
    "          \"endDateIso\": end_date_iso,\n",
    "          \"paginationOption\": {}\n",
    "        })\n",
    "        \n",
    "        response = requests.request(\"POST\", url, headers=self.headers, data=payload)\n",
    "        data = response.json()\n",
    "\n",
    "        rides = data['data']['activities']\n",
    "        while data['data']['pagination']['hasMoreData']:\n",
    "            payload = json.dumps({\n",
    "              \"startDateIso\": start_date_iso,\n",
    "              \"endDateIso\": end_date_iso,\n",
    "              \"paginationOption\": {\"cursor\": data['data']['pagination']['nextCursor']}\n",
    "            })\n",
    "            response = requests.request(\"POST\", url, headers=self.headers, data=payload)\n",
    "            data = response.json()\n",
    "            if data['data']['activities']:\n",
    "                rides = rides + data['data']['activities']\n",
    "        return rides or []\n",
    "\n",
    "    def get_ride_detail(self, ride_uuid):\n",
    "        # This is only helpful to get additional fare breakdown from Uber, if we wanted to analyze how much\n",
    "        # Uber is taking from each fare.\n",
    "        url = f\"https://drivers.uber.com/earnings/trips/{ride_uuid}\"\n",
    "        response = requests.request(\"GET\", url, headers=self.headers)\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ce03ce-e280-4f38-ad1a-9db36be7ccaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting rides for 2023-01-09 - 2023-01-16...\n",
      "Retrieved 42 rides.\n",
      "Getting rides for 2023-01-16 - 2023-01-23...\n",
      "Retrieved 9 rides.\n",
      "Getting rides for 2023-01-23 - 2023-01-30...\n",
      "Retrieved 13 rides.\n",
      "Getting rides for 2023-01-30 - 2023-02-06...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-02-06 - 2023-02-13...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-02-13 - 2023-02-20...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-02-20 - 2023-02-27...\n",
      "Retrieved 7 rides.\n",
      "Getting rides for 2023-02-27 - 2023-03-06...\n",
      "Retrieved 29 rides.\n",
      "Getting rides for 2023-03-06 - 2023-03-13...\n",
      "Retrieved 9 rides.\n",
      "Getting rides for 2023-03-13 - 2023-03-20...\n",
      "Retrieved 51 rides.\n",
      "Getting rides for 2023-03-20 - 2023-03-27...\n",
      "Retrieved 59 rides.\n",
      "Getting rides for 2023-03-27 - 2023-04-03...\n",
      "Retrieved 26 rides.\n",
      "Getting rides for 2023-04-03 - 2023-04-10...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-10 - 2023-04-17...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-17 - 2023-04-24...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-04-24 - 2023-05-01...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-05-01 - 2023-05-08...\n",
      "Retrieved 6 rides.\n",
      "Getting rides for 2023-05-08 - 2023-05-15...\n",
      "Retrieved 11 rides.\n",
      "Getting rides for 2023-05-15 - 2023-05-22...\n",
      "Retrieved 3 rides.\n",
      "Getting rides for 2023-05-22 - 2023-05-29...\n",
      "Retrieved 19 rides.\n",
      "Getting rides for 2023-05-29 - 2023-06-05...\n",
      "Retrieved 14 rides.\n",
      "Getting rides for 2023-06-05 - 2023-06-12...\n",
      "Retrieved 11 rides.\n",
      "Getting rides for 2023-06-12 - 2023-06-19...\n",
      "Retrieved 1 rides.\n",
      "Getting rides for 2023-06-19 - 2023-06-26...\n",
      "Retrieved 18 rides.\n",
      "Getting rides for 2023-06-26 - 2023-07-03...\n",
      "Retrieved 3 rides.\n",
      "Getting rides for 2023-07-03 - 2023-07-10...\n",
      "Retrieved 12 rides.\n",
      "Getting rides for 2023-07-10 - 2023-07-17...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-07-17 - 2023-07-24...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-07-24 - 2023-07-31...\n",
      "Retrieved 18 rides.\n",
      "Getting rides for 2023-07-31 - 2023-08-07...\n",
      "Retrieved 41 rides.\n",
      "Getting rides for 2023-08-07 - 2023-08-14...\n",
      "Retrieved 34 rides.\n",
      "Getting rides for 2023-08-14 - 2023-08-21...\n",
      "Retrieved 45 rides.\n",
      "Getting rides for 2023-08-21 - 2023-08-28...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2023-08-28 - 2023-09-04...\n",
      "Retrieved 39 rides.\n",
      "Getting rides for 2023-09-04 - 2023-09-11...\n",
      "Retrieved 30 rides.\n",
      "Getting rides for 2023-09-11 - 2023-09-18...\n",
      "Retrieved 37 rides.\n",
      "Getting rides for 2023-09-18 - 2023-09-25...\n",
      "Retrieved 33 rides.\n",
      "Getting rides for 2023-09-25 - 2023-10-02...\n",
      "Retrieved 0 rides.\n",
      "Getting rides for 2023-10-02 - 2023-10-09...\n",
      "Retrieved 65 rides.\n",
      "Getting rides for 2023-10-09 - 2023-10-16...\n",
      "Retrieved 63 rides.\n",
      "Getting rides for 2023-10-16 - 2023-10-23...\n",
      "Retrieved 36 rides.\n",
      "Getting rides for 2023-10-23 - 2023-10-30...\n",
      "Retrieved 62 rides.\n",
      "Getting rides for 2023-10-30 - 2023-11-06...\n",
      "Retrieved 54 rides.\n",
      "Getting rides for 2023-11-06 - 2023-11-13...\n",
      "Retrieved 81 rides.\n",
      "Getting rides for 2023-11-13 - 2023-11-20...\n",
      "Retrieved 49 rides.\n",
      "Getting rides for 2023-11-20 - 2023-11-27...\n",
      "Retrieved 36 rides.\n",
      "Getting rides for 2023-11-27 - 2023-12-04...\n",
      "Retrieved 102 rides.\n",
      "Getting rides for 2023-12-04 - 2023-12-11...\n",
      "Retrieved 91 rides.\n",
      "Getting rides for 2023-12-11 - 2023-12-18...\n",
      "Retrieved 101 rides.\n",
      "Getting rides for 2023-12-18 - 2023-12-25...\n",
      "Retrieved 103 rides.\n",
      "Getting rides for 2023-12-25 - 2024-01-01...\n",
      "Retrieved 100 rides.\n",
      "Getting rides for 2024-01-01 - 2024-01-08...\n",
      "Retrieved 154 rides.\n",
      "Getting rides for 2024-01-08 - 2024-01-15...\n",
      "Retrieved 65 rides.\n",
      "Getting rides for 2024-01-15 - 2024-01-22...\n",
      "Retrieved 56 rides.\n",
      "Getting rides for 2024-01-22 - 2024-01-29...\n",
      "Retrieved 77 rides.\n",
      "Getting rides for 2024-01-29 - 2024-02-05...\n",
      "Retrieved 96 rides.\n",
      "Getting rides for 2024-02-05 - 2024-02-12...\n",
      "Retrieved 57 rides.\n",
      "Getting rides for 2024-02-12 - 2024-02-19...\n",
      "Retrieved 85 rides.\n",
      "Getting rides for 2024-02-19 - 2024-02-26...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2024-02-26 - 2024-03-04...\n",
      "Retrieved 61 rides.\n",
      "Getting rides for 2024-03-04 - 2024-03-11...\n",
      "Retrieved 88 rides.\n",
      "Getting rides for 2024-03-11 - 2024-03-18...\n",
      "Retrieved 133 rides.\n",
      "Getting rides for 2024-03-18 - 2024-03-25...\n",
      "Retrieved 85 rides.\n",
      "Getting rides for 2024-03-25 - 2024-04-01...\n",
      "Retrieved 127 rides.\n",
      "Getting rides for 2024-04-01 - 2024-04-08...\n",
      "Retrieved 97 rides.\n",
      "Getting rides for 2024-04-08 - 2024-04-15...\n",
      "Retrieved 97 rides.\n",
      "Getting rides for 2024-04-15 - 2024-04-22...\n",
      "Retrieved 50 rides.\n",
      "Getting rides for 2024-04-22 - 2024-04-29...\n",
      "Retrieved 63 rides.\n",
      "Getting rides for 2024-04-29 - 2024-05-06...\n",
      "Retrieved 71 rides.\n",
      "Getting rides for 2024-05-06 - 2024-05-13...\n",
      "Retrieved 89 rides.\n",
      "Getting rides for 2024-05-13 - 2024-05-20...\n",
      "Retrieved 77 rides.\n",
      "Getting rides for 2024-05-20 - 2024-05-27...\n",
      "Retrieved 70 rides.\n",
      "Getting rides for 2024-05-27 - 2024-06-03...\n",
      "Retrieved 74 rides.\n",
      "Getting rides for 2024-06-03 - 2024-06-10...\n",
      "Retrieved 58 rides.\n",
      "Getting rides for 2024-06-10 - 2024-06-17...\n",
      "Retrieved 42 rides.\n",
      "Getting rides for 2024-06-17 - 2024-06-24...\n",
      "Retrieved 75 rides.\n",
      "Getting rides for 2024-06-24 - 2024-07-01...\n",
      "Retrieved 78 rides.\n",
      "Getting rides for 2024-07-01 - 2024-07-08...\n",
      "Retrieved 44 rides.\n",
      "Getting rides for 2024-07-08 - 2024-07-15...\n",
      "Retrieved 35 rides.\n",
      "Getting rides for 2024-07-15 - 2024-07-22...\n",
      "Retrieved 15 rides.\n",
      "Getting rides for 2024-07-22 - 2024-07-29...\n",
      "Retrieved 27 rides.\n",
      "Getting rides for 2024-07-29 - 2024-08-05...\n",
      "Retrieved 30 rides.\n",
      "Getting rides for 2024-08-05 - 2024-08-12...\n",
      "Retrieved 106 rides.\n",
      "Getting rides for 2024-08-12 - 2024-08-19...\n",
      "Retrieved 123 rides.\n",
      "Getting rides for 2024-08-19 - 2024-08-26...\n",
      "Retrieved 113 rides.\n",
      "Retrieved 4249 rides total.\n"
     ]
    }
   ],
   "source": [
    "uber = UberDriver()\n",
    "\n",
    "# This is the date I started working as an Uber driver; modify for your start date\n",
    "start_date = datetime.strptime(\"2023-01-09\", \"%Y-%m-%d\")\n",
    "end_date = datetime.today()\n",
    "current_date = start_date\n",
    "\n",
    "rides = []\n",
    "while current_date <= end_date:\n",
    "    next_date = current_date + timedelta(days = 7)\n",
    "    start_date_iso = current_date.strftime('%Y-%m-%d')\n",
    "    end_date_iso = next_date.strftime('%Y-%m-%d')\n",
    "    print(f\"Getting rides for {start_date_iso} - {end_date_iso}...\")\n",
    "    new_rides = uber.get_rides(start_date_iso, end_date_iso)\n",
    "    print(f\"Retrieved {len(new_rides)} rides.\")\n",
    "    rides += new_rides\n",
    "    current_date = next_date\n",
    "\n",
    "# Let's dump all of these rides to a JSON file so we can reference this data outside of the script if need be, \n",
    "# or simply not have to retrieve from Uber again.\n",
    "with open(f\"rides.json\", \"w\") as file:\n",
    "    json.dump(rides, file)\n",
    "\n",
    "print(f\"Retrieved {len(rides)} rides total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a9f937-fd54-4205-841b-195e1b2fb0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      uuid  recognizedAt   activityTitle  \\\n",
      "0     d3096d6c-02bd-4f8e-855b-117588b27910    1673809557         Comfort   \n",
      "1     89a3e777-2000-44af-8509-765b157dfe9e    1673808331           UberX   \n",
      "2     78616fc5-6214-4f31-89a0-4229e35f0c5c    1673807621           UberX   \n",
      "3     b6457299-8e46-44ec-b151-398649205336    1673806661           UberX   \n",
      "4     ae817bfc-76a2-4a47-8622-d85cc9b5dd8e    1673802749           UberX   \n",
      "...                                    ...           ...             ...   \n",
      "4244  eeb105cb-7abd-43d3-8987-7d5bf5bceadc    1724101706           UberX   \n",
      "4245  e56b225b-9b01-4fc1-b2dc-a8b5de54519a    1724098587           UberX   \n",
      "4246  b9d51f86-f612-4853-84ba-0f98885103dd    1724096867           UberX   \n",
      "4247  56012ec9-9d96-42ad-a0e7-1260af304ada    1724095014           UberX   \n",
      "4248  91178c7b-91c5-5c46-914c-7618c524f208    1724058000  {0} Trip Quest   \n",
      "\n",
      "     formattedTotal                                            routing  \\\n",
      "0            $10.72  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "1             $4.13  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "2             $7.56  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "3            $11.19  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4            $10.48  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "...             ...                                                ...   \n",
      "4244         $15.91  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4245          $6.09  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4246         $11.95  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4247         $12.19  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "4248          $0.00  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "\n",
      "                                       breakdownDetails  \\\n",
      "0     {'formattedTip': '$1.00', 'formattedSurge': None}   \n",
      "1                                                  None   \n",
      "2     {'formattedTip': '$3.00', 'formattedSurge': None}   \n",
      "3     {'formattedTip': '$3.00', 'formattedSurge': '$...   \n",
      "4     {'formattedTip': '$3.00', 'formattedSurge': None}   \n",
      "...                                                 ...   \n",
      "4244  {'formattedTip': '$5.00', 'formattedSurge': None}   \n",
      "4245                                               None   \n",
      "4246                                               None   \n",
      "4247                                               None   \n",
      "4248                                               None   \n",
      "\n",
      "                                           tripMetaData   type     status  \n",
      "0     {'formattedDuration': '15 min 56 sec', 'format...   TRIP  COMPLETED  \n",
      "1     {'formattedDuration': '13 min 55 sec', 'format...   TRIP  COMPLETED  \n",
      "2     {'formattedDuration': '10 min 42 sec', 'format...   TRIP  COMPLETED  \n",
      "3     {'formattedDuration': '11 min 53 sec', 'format...   TRIP  COMPLETED  \n",
      "4     {'formattedDuration': '21 min 57 sec', 'format...   TRIP  COMPLETED  \n",
      "...                                                 ...    ...        ...  \n",
      "4244  {'formattedDuration': '21 min 46 sec', 'format...   TRIP  COMPLETED  \n",
      "4245  {'formattedDuration': '10 min 16 sec', 'format...   TRIP  COMPLETED  \n",
      "4246  {'formattedDuration': '22 min 30 sec', 'format...   TRIP  COMPLETED  \n",
      "4247  {'formattedDuration': '27 min 21 sec', 'format...   TRIP  COMPLETED  \n",
      "4248                                               None  QUEST       None  \n",
      "\n",
      "[4249 rows x 9 columns]\n",
      "                                   uuid  recognizedAt activityTitle  \\\n",
      "0  d3096d6c-02bd-4f8e-855b-117588b27910    1673809557       Comfort   \n",
      "\n",
      "  formattedTotal                                            routing  \\\n",
      "0         $10.72  {'webviewUrl': 'https://drivers.uber.com/earni...   \n",
      "\n",
      "                                    breakdownDetails  \\\n",
      "0  {'formattedTip': '$1.00', 'formattedSurge': None}   \n",
      "\n",
      "                                        tripMetaData  type     status  \n",
      "0  {'formattedDuration': '15 min 56 sec', 'format...  TRIP  COMPLETED  \n",
      "['TRIP' 'MISC' 'CT' 'QUEST']\n",
      "['Comfort' 'UberX' 'Connect Express' 'UberXL' 'Time Adjustment'\n",
      " 'UberX Share' 'Delivery' 'Connect Saver' 'Adjustment' 'Quest'\n",
      " 'Miscellaneous Adjustment' 'Lost Item Return' 'UberX Priority' 'Uber Pet'\n",
      " 'Incentive' '{0} Trip Quest' 'Package Express' 'Business Comfort'\n",
      " 'Payment for past trip']\n"
     ]
    }
   ],
   "source": [
    "# Let's re-load rides using what's in the JSON file to confirm that it's what we need.\n",
    "# We can also re-run from this point onward without having to hit the Uber site again.\n",
    "with open(f\"rides.json\", \"r\") as file:\n",
    "    rides = json.load(file)\n",
    "\n",
    "rides_df = pd.read_json('rides.json')\n",
    "\n",
    "# Let's see what the ride data looks like\n",
    "print(rides_df)\n",
    "print(rides_df.head(1))\n",
    "print(rides_df['type'].unique())\n",
    "print(rides_df['activityTitle'].unique())\n",
    "\n",
    "# The rest of the code was already written to process a list of dicts, not a dataframe\n",
    "rides = rides_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc753e16-1bdb-46d1-a4b2-6ae7cde57668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_to_seconds(time_str):\n",
    "    matches = re.findall(r'(\\d+)\\s*(hr|min|sec)', time_str)\n",
    "    unit_to_seconds = {'hr': 3600, 'min': 60, 'sec': 1}\n",
    "    return sum(int(value) * unit_to_seconds[unit] for value, unit in matches)\n",
    "\n",
    "def parse_miles(miles_str):\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*mi', miles_str)\n",
    "    return float(match.group(1))\n",
    "\n",
    "def parse_currency_to_float(currency_str):\n",
    "    clean_str = currency_str.replace('$', '').strip()\n",
    "    return float(clean_str)\n",
    "\n",
    "def parse_season(date):\n",
    "    \"\"\"Return the season for a given datetime object.\"\"\"\n",
    "    seasons = {\n",
    "        'Spring': (3, 21, 6, 20),\n",
    "        'Summer': (6, 21, 9, 20),\n",
    "        'Fall': (9, 21, 12, 20),\n",
    "        'Winter': (12, 21, 3, 20)\n",
    "    }\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    for season, (start_month, start_day, end_month, end_day) in seasons.items():\n",
    "        if start_month <= end_month:\n",
    "            if start_month <= month <= end_month:\n",
    "                if (month == start_month and day >= start_day) or (month == end_month and day <= end_day) or (start_month < month < end_month):\n",
    "                    return season\n",
    "        else:\n",
    "            if month > start_month or month < end_month or (month == start_month and day >= start_day) or (month == end_month and day <= end_day):\n",
    "                return season\n",
    "\n",
    "def extract_zipcode(address):\n",
    "    zip_code_pattern = re.compile(r'\\b\\d{5}\\b')\n",
    "    match = zip_code_pattern.search(address)\n",
    "    if match:\n",
    "        return match.group()\n",
    "\n",
    "cleaned_rides = []\n",
    "for ride in rides:\n",
    "    if ride.get('breakdownDetails'):\n",
    "        tip = ride['breakdownDetails']['formattedTip'] or '$0.00'\n",
    "        surge = ride['breakdownDetails']['formattedSurge'] or '$0.00'\n",
    "    else:\n",
    "        tip = '$0.00'\n",
    "        surge = '$0.00'\n",
    "    if ride.get('tripMetaData'):\n",
    "        duration = parse_time_to_seconds(ride['tripMetaData']['formattedDuration'])\n",
    "        distance = parse_miles(ride['tripMetaData']['formattedDistance'])\n",
    "        pickup_address = ride['tripMetaData']['pickupAddress']\n",
    "        dropoff_address = ride['tripMetaData']['dropOffAddress']\n",
    "    else:\n",
    "        duration = None\n",
    "        distance = None\n",
    "        pickup_address = None\n",
    "        dropoff_address = None\n",
    "    when = datetime.fromtimestamp(ride['recognizedAt'])\n",
    "    ride_clean = {\n",
    "        'uuid': ride['uuid'],\n",
    "        'date': when.strftime('%Y-%m-%d'),\n",
    "        'time': when.strftime('%H:%M:%S'),\n",
    "        'timestamp': ride['recognizedAt'],\n",
    "        'day': when.strftime('%A'),\n",
    "        'day_of_week': when.weekday(),\n",
    "        'sortable_day_of_week': f\"{when.weekday()} - {when.strftime('%A')}\",\n",
    "        'season': parse_season(when),\n",
    "        'type': ride['activityTitle'],\n",
    "        'earnings': parse_currency_to_float(ride['formattedTotal']),\n",
    "        'tip': parse_currency_to_float(tip),\n",
    "        'surge': parse_currency_to_float(surge),\n",
    "        'duration': duration,\n",
    "        'distance': distance,\n",
    "        'pickup_address': pickup_address,\n",
    "        'dropoff_address': dropoff_address,\n",
    "        'status': ride['status'],\n",
    "        'note': ride['type']\n",
    "    }\n",
    "    cleaned_rides.append(ride_clean)\n",
    "\n",
    "# Let's filter the data to only include completed rides of humans\n",
    "filtered_rides = [ride for ride in cleaned_rides if ride['status'] == 'COMPLETED' \n",
    "                                                 and ride['note'] == 'TRIP' \n",
    "                                                 and ride['type'] in ['Comfort', 'UberX', 'UberXL', 'UberX Share', \n",
    "                                                                      'UberX Priority', 'Uber Pet', 'Business Comfort']]\n",
    "\n",
    "# Let's add some calculated columns now to skip the manual processing in a spreadsheet\n",
    "enriched_rides = []\n",
    "for ride in filtered_rides:\n",
    "    ride = ride.copy()\n",
    "    ride['earnings-surge'] = ride['earnings'] - ride['surge']\n",
    "    ride['earnings/second'] = ride['earnings'] / ride['duration']\n",
    "    ride['earnings/mile'] = ride['earnings'] / ride['distance']\n",
    "    ride['pickup_zipcode'] = extract_zipcode(ride['pickup_address'])\n",
    "    ride['dropoff_zipcode'] = extract_zipcode(ride['dropoff_address'])\n",
    "    del ride['status']\n",
    "    del ride['note']\n",
    "    enriched_rides.append(ride)\n",
    "\n",
    "with open('enriched_rides.json', 'w') as f:\n",
    "    f.write(json.dumps(enriched_rides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4727b85-c6fe-44a6-9c0a-e1b9bdbd3370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          timestamp  day_of_week     earnings          tip        surge  \\\n",
      "count  3.657000e+03  3657.000000  3657.000000  3657.000000  3657.000000   \n",
      "mean   1.706210e+09     3.135630    11.447104     1.509284     0.714315   \n",
      "std    1.197818e+07     1.739357     6.950630     2.568006     1.557651   \n",
      "min    1.673391e+09     0.000000     2.860000     0.000000     0.000000   \n",
      "25%    1.699843e+09     2.000000     6.760000     0.000000     0.000000   \n",
      "50%    1.707350e+09     3.000000     9.890000     0.000000     0.000000   \n",
      "75%    1.715110e+09     5.000000    14.040000     3.000000     1.000000   \n",
      "max    1.724459e+09     6.000000   105.860000    28.780000    14.000000   \n",
      "\n",
      "          duration     distance  earnings-surge  earnings/second  \\\n",
      "count  3657.000000  3657.000000     3657.000000      3657.000000   \n",
      "mean   1033.619087     4.547990       10.732789         0.012302   \n",
      "std     664.837903     4.038747        6.430917         0.005502   \n",
      "min      87.000000     0.200000        2.800000         0.004597   \n",
      "25%     582.000000     2.000000        6.450000         0.008773   \n",
      "50%     872.000000     3.400000        9.240000         0.010925   \n",
      "75%    1303.000000     5.800000       13.120000         0.014175   \n",
      "max    7620.000000    47.900000       92.860000         0.083681   \n",
      "\n",
      "       earnings/mile  \n",
      "count    3657.000000  \n",
      "mean        3.340933  \n",
      "std         2.053738  \n",
      "min         0.759401  \n",
      "25%         2.096923  \n",
      "50%         2.820000  \n",
      "75%         3.916667  \n",
      "max        23.333333  \n",
      "                                        uuid        date      time  \\\n",
      "count                                   3657        3657      3657   \n",
      "unique                                  3657         321      3525   \n",
      "top     d3096d6c-02bd-4f8e-855b-117588b27910  2024-08-15  18:47:29   \n",
      "freq                                       1          36         3   \n",
      "mean                                     NaN         NaN       NaN   \n",
      "std                                      NaN         NaN       NaN   \n",
      "min                                      NaN         NaN       NaN   \n",
      "25%                                      NaN         NaN       NaN   \n",
      "50%                                      NaN         NaN       NaN   \n",
      "75%                                      NaN         NaN       NaN   \n",
      "max                                      NaN         NaN       NaN   \n",
      "\n",
      "           timestamp     day  day_of_week sortable_day_of_week  season   type  \\\n",
      "count   3.657000e+03    3657  3657.000000                 3657    3657   3657   \n",
      "unique           NaN       7          NaN                    7       4      6   \n",
      "top              NaN  Friday          NaN           4 - Friday  Winter  UberX   \n",
      "freq             NaN     799          NaN                  799    1174   3358   \n",
      "mean    1.706210e+09     NaN     3.135630                  NaN     NaN    NaN   \n",
      "std     1.197818e+07     NaN     1.739357                  NaN     NaN    NaN   \n",
      "min     1.673391e+09     NaN     0.000000                  NaN     NaN    NaN   \n",
      "25%     1.699843e+09     NaN     2.000000                  NaN     NaN    NaN   \n",
      "50%     1.707350e+09     NaN     3.000000                  NaN     NaN    NaN   \n",
      "75%     1.715110e+09     NaN     5.000000                  NaN     NaN    NaN   \n",
      "max     1.724459e+09     NaN     6.000000                  NaN     NaN    NaN   \n",
      "\n",
      "           earnings  ...        surge     duration     distance  \\\n",
      "count   3657.000000  ...  3657.000000  3657.000000  3657.000000   \n",
      "unique          NaN  ...          NaN          NaN          NaN   \n",
      "top             NaN  ...          NaN          NaN          NaN   \n",
      "freq            NaN  ...          NaN          NaN          NaN   \n",
      "mean      11.447104  ...     0.714315  1033.619087     4.547990   \n",
      "std        6.950630  ...     1.557651   664.837903     4.038747   \n",
      "min        2.860000  ...     0.000000    87.000000     0.200000   \n",
      "25%        6.760000  ...     0.000000   582.000000     2.000000   \n",
      "50%        9.890000  ...     0.000000   872.000000     3.400000   \n",
      "75%       14.040000  ...     1.000000  1303.000000     5.800000   \n",
      "max      105.860000  ...    14.000000  7620.000000    47.900000   \n",
      "\n",
      "                                pickup_address  \\\n",
      "count                                     3657   \n",
      "unique                                    2526   \n",
      "top     N Milwaukee Ave, Chicago, IL 60647, US   \n",
      "freq                                        34   \n",
      "mean                                       NaN   \n",
      "std                                        NaN   \n",
      "min                                        NaN   \n",
      "25%                                        NaN   \n",
      "50%                                        NaN   \n",
      "75%                                        NaN   \n",
      "max                                        NaN   \n",
      "\n",
      "                               dropoff_address earnings-surge  \\\n",
      "count                                     3657    3657.000000   \n",
      "unique                                    2508            NaN   \n",
      "top     N Milwaukee Ave, Chicago, IL 60647, US            NaN   \n",
      "freq                                        26            NaN   \n",
      "mean                                       NaN      10.732789   \n",
      "std                                        NaN       6.430917   \n",
      "min                                        NaN       2.800000   \n",
      "25%                                        NaN       6.450000   \n",
      "50%                                        NaN       9.240000   \n",
      "75%                                        NaN      13.120000   \n",
      "max                                        NaN      92.860000   \n",
      "\n",
      "        earnings/second  earnings/mile  pickup_zipcode dropoff_zipcode  \n",
      "count       3657.000000    3657.000000            3657            3656  \n",
      "unique              NaN            NaN             105             119  \n",
      "top                 NaN            NaN           60647           60614  \n",
      "freq                NaN            NaN             321             241  \n",
      "mean           0.012302       3.340933             NaN             NaN  \n",
      "std            0.005502       2.053738             NaN             NaN  \n",
      "min            0.004597       0.759401             NaN             NaN  \n",
      "25%            0.008773       2.096923             NaN             NaN  \n",
      "50%            0.010925       2.820000             NaN             NaN  \n",
      "75%            0.014175       3.916667             NaN             NaN  \n",
      "max            0.083681      23.333333             NaN             NaN  \n",
      "\n",
      "[11 rows x 21 columns]\n",
      "\n",
      "Count of None values per column:\n",
      " uuid                    0\n",
      "date                    0\n",
      "time                    0\n",
      "timestamp               0\n",
      "day                     0\n",
      "day_of_week             0\n",
      "sortable_day_of_week    0\n",
      "season                  0\n",
      "type                    0\n",
      "earnings                0\n",
      "tip                     0\n",
      "surge                   0\n",
      "duration                0\n",
      "distance                0\n",
      "pickup_address          0\n",
      "dropoff_address         0\n",
      "earnings-surge          0\n",
      "earnings/second         0\n",
      "earnings/mile           0\n",
      "pickup_zipcode          0\n",
      "dropoff_zipcode         1\n",
      "dtype: int64\n",
      "\n",
      "Additional Info:\n",
      "Unique values in column 'uuid' (#3657): ['d3096d6c-02bd-4f8e-855b-117588b27910'\n",
      " '89a3e777-2000-44af-8509-765b157dfe9e'\n",
      " '78616fc5-6214-4f31-89a0-4229e35f0c5c' ...\n",
      " 'e56b225b-9b01-4fc1-b2dc-a8b5de54519a'\n",
      " 'b9d51f86-f612-4853-84ba-0f98885103dd'\n",
      " '56012ec9-9d96-42ad-a0e7-1260af304ada']\n",
      "Unique values in column 'date' (#321): ['2023-01-15' '2023-01-14' '2023-01-13' '2023-01-10' '2023-01-20'\n",
      " '2023-01-17' '2023-01-26' '2023-02-10' '2023-02-09' '2023-02-19'\n",
      " '2023-02-18' '2023-02-14' '2023-02-22' '2023-03-03' '2023-03-01'\n",
      " '2023-03-12' '2023-03-18' '2023-03-17' '2023-03-16' '2023-03-14'\n",
      " '2023-03-13' '2023-03-26' '2023-03-25' '2023-03-24' '2023-03-22'\n",
      " '2023-03-21' '2023-03-20' '2023-04-01' '2023-03-31' '2023-03-30'\n",
      " '2023-03-28' '2023-05-04' '2023-05-12' '2023-05-21' '2023-05-28'\n",
      " '2023-05-26' '2023-05-25' '2023-06-03' '2023-06-02' '2023-05-29'\n",
      " '2023-06-10' '2023-06-09' '2023-06-25' '2023-06-24' '2023-06-27'\n",
      " '2023-07-08' '2023-07-07' '2023-07-06' '2023-07-05' '2023-07-29'\n",
      " '2023-07-28' '2023-08-06' '2023-08-05' '2023-08-03' '2023-08-02'\n",
      " '2023-08-01' '2023-08-12' '2023-08-11' '2023-08-08' '2023-08-20'\n",
      " '2023-08-19' '2023-08-18' '2023-08-17' '2023-08-16' '2023-08-15'\n",
      " '2023-08-26' '2023-08-25' '2023-08-24' '2023-08-23' '2023-08-22'\n",
      " '2023-08-21' '2023-09-01' '2023-08-31' '2023-08-30' '2023-08-29'\n",
      " '2023-08-28' '2023-09-07' '2023-09-06' '2023-09-05' '2023-09-16'\n",
      " '2023-09-15' '2023-09-14' '2023-09-12' '2023-09-11' '2023-09-22'\n",
      " '2023-09-21' '2023-10-08' '2023-10-07' '2023-10-06' '2023-10-05'\n",
      " '2023-10-04' '2023-10-03' '2023-10-02' '2023-10-14' '2023-10-13'\n",
      " '2023-10-12' '2023-10-11' '2023-10-21' '2023-10-20' '2023-10-18'\n",
      " '2023-10-16' '2023-10-27' '2023-10-26' '2023-10-25' '2023-10-24'\n",
      " '2023-10-23' '2023-11-04' '2023-11-03' '2023-11-01' '2023-10-31'\n",
      " '2023-11-12' '2023-11-11' '2023-11-09' '2023-11-08' '2023-11-07'\n",
      " '2023-11-06' '2023-11-17' '2023-11-16' '2023-11-15' '2023-11-14'\n",
      " '2023-11-13' '2023-11-26' '2023-11-23' '2023-11-21' '2023-11-20'\n",
      " '2023-12-03' '2023-12-01' '2023-11-30' '2023-11-29' '2023-11-28'\n",
      " '2023-11-27' '2023-12-10' '2023-12-09' '2023-12-08' '2023-12-07'\n",
      " '2023-12-06' '2023-12-05' '2023-12-04' '2023-12-16' '2023-12-15'\n",
      " '2023-12-14' '2023-12-13' '2023-12-12' '2023-12-11' '2023-12-23'\n",
      " '2023-12-22' '2023-12-21' '2023-12-20' '2023-12-19' '2023-12-18'\n",
      " '2023-12-31' '2023-12-30' '2023-12-29' '2023-12-28' '2023-12-27'\n",
      " '2024-01-07' '2024-01-06' '2024-01-05' '2024-01-04' '2024-01-03'\n",
      " '2024-01-01' '2024-01-14' '2024-01-13' '2024-01-11' '2024-01-09'\n",
      " '2024-01-08' '2024-01-19' '2024-01-18' '2024-01-16' '2024-01-27'\n",
      " '2024-01-26' '2024-01-25' '2024-01-24' '2024-01-22' '2024-02-03'\n",
      " '2024-02-02' '2024-02-01' '2024-01-31' '2024-01-30' '2024-01-29'\n",
      " '2024-02-11' '2024-02-10' '2024-02-09' '2024-02-07' '2024-02-06'\n",
      " '2024-02-18' '2024-02-17' '2024-02-16' '2024-02-15' '2024-02-14'\n",
      " '2024-02-12' '2024-02-24' '2024-02-23' '2024-02-22' '2024-02-21'\n",
      " '2024-02-20' '2024-03-02' '2024-03-01' '2024-02-29' '2024-02-28'\n",
      " '2024-02-27' '2024-03-09' '2024-03-08' '2024-03-07' '2024-03-06'\n",
      " '2024-03-05' '2024-03-16' '2024-03-15' '2024-03-14' '2024-03-13'\n",
      " '2024-03-11' '2024-03-23' '2024-03-22' '2024-03-20' '2024-03-19'\n",
      " '2024-03-18' '2024-03-31' '2024-03-30' '2024-03-29' '2024-03-28'\n",
      " '2024-03-27' '2024-03-26' '2024-04-06' '2024-04-05' '2024-04-04'\n",
      " '2024-04-03' '2024-04-02' '2024-04-14' '2024-04-12' '2024-04-10'\n",
      " '2024-04-09' '2024-04-08' '2024-04-21' '2024-04-20' '2024-04-19'\n",
      " '2024-04-28' '2024-04-27' '2024-04-26' '2024-04-24' '2024-04-23'\n",
      " '2024-05-05' '2024-05-04' '2024-05-03' '2024-05-02' '2024-05-01'\n",
      " '2024-04-30' '2024-05-12' '2024-05-11' '2024-05-10' '2024-05-09'\n",
      " '2024-05-08' '2024-05-07' '2024-05-19' '2024-05-18' '2024-05-17'\n",
      " '2024-05-15' '2024-05-25' '2024-05-24' '2024-05-23' '2024-05-22'\n",
      " '2024-05-21' '2024-05-20' '2024-06-02' '2024-06-01' '2024-05-31'\n",
      " '2024-05-30' '2024-05-29' '2024-05-27' '2024-06-08' '2024-06-07'\n",
      " '2024-06-06' '2024-06-05' '2024-06-04' '2024-06-16' '2024-06-15'\n",
      " '2024-06-14' '2024-06-13' '2024-06-11' '2024-06-22' '2024-06-21'\n",
      " '2024-06-20' '2024-06-19' '2024-06-29' '2024-06-28' '2024-06-26'\n",
      " '2024-06-24' '2024-07-07' '2024-07-06' '2024-07-05' '2024-07-14'\n",
      " '2024-07-13' '2024-07-11' '2024-07-09' '2024-07-17' '2024-07-16'\n",
      " '2024-07-27' '2024-07-26' '2024-07-25' '2024-07-23' '2024-08-03'\n",
      " '2024-08-02' '2024-08-01' '2024-07-31' '2024-08-10' '2024-08-09'\n",
      " '2024-08-08' '2024-08-07' '2024-08-06' '2024-08-05' '2024-08-18'\n",
      " '2024-08-17' '2024-08-16' '2024-08-15' '2024-08-14' '2024-08-13'\n",
      " '2024-08-12' '2024-08-23' '2024-08-22' '2024-08-21' '2024-08-20'\n",
      " '2024-08-19']\n",
      "Unique values in column 'time' (#3525): ['13:05:57' '12:45:31' '12:33:41' ... '15:16:27' '14:47:47' '14:16:54']\n",
      "Unique values in column 'day' (#7): ['Sunday' 'Saturday' 'Friday' 'Tuesday' 'Thursday' 'Wednesday' 'Monday']\n",
      "Unique values in column 'sortable_day_of_week' (#7): ['6 - Sunday' '5 - Saturday' '4 - Friday' '1 - Tuesday' '3 - Thursday'\n",
      " '2 - Wednesday' '0 - Monday']\n",
      "Unique values in column 'season' (#4): ['Winter' 'Spring' 'Summer' 'Fall']\n",
      "Unique values in column 'type' (#6): ['Comfort' 'UberX' 'UberXL' 'UberX Priority' 'Uber Pet' 'Business Comfort']\n",
      "Unique values in column 'pickup_address' (#2526): ['N Ashland Ave, Chicago, IL 60614-1101, US'\n",
      " 'N Lincoln Ave, Chicago, IL 60613, US'\n",
      " 'N Clifton Ave, Chicago, IL 60657-3318, US' ...\n",
      " 'W Dickens Ave, Chicago, IL 60647-4521, US'\n",
      " 'W Leland Ave, Chicago, IL 60625, US'\n",
      " 'W Wallen Ave, Chicago, IL 60626-6624, US']\n",
      "Unique values in column 'dropoff_address' (#2508): ['W Madison St, Chicago, IL 60612, US'\n",
      " 'N Southport Ave, Chicago, IL 60614, US'\n",
      " 'N Lincoln Ave, Chicago, IL 60613, US' ...\n",
      " 'N Hoyne Ave, Chicago, IL 60622-4901, US'\n",
      " 'W Huron St, Chicago, IL 60654-3712, US'\n",
      " 'W Lawrence Ave, Chicago, IL 60625-5726, US']\n",
      "Unique values in column 'pickup_zipcode' (#105): ['60614' '60613' '60657' '60647' '60661' '60640' '60641' '60634' '60626'\n",
      " '60625' '60622' '60201' '60091' '60712' '60610' '60607' '60654' '60618'\n",
      " '60660' '60202' '60605' '60645' '60611' '60666' '60644' '60624' '60612'\n",
      " '60155' '60093' '60045' '60616' '60076' '60608' '60603' '60620' '60615'\n",
      " '60653' '60636' '60637' '60131' '60659' '60646' '60053' '60631' '60621'\n",
      " '60606' '60409' '60501' '60629' '60402' '60804' '60638' '60164' '60523'\n",
      " '60651' '60706' '60656' '60803' '60077' '60632' '60609' '60649' '60639'\n",
      " '60016' '60707' '60630' '60714' '60546' '60601' '60160' '60176' '60089'\n",
      " '60208' '60126' '60025' '60628' '60515' '60619' '60652' '60456' '60018'\n",
      " '60642' '60534' '60104' '60062' '60120' '60623' '60602' '60068' '60604'\n",
      " '46394' '60069' '60040' '60005' '60302' '60101' '60123' '60561' '60513'\n",
      " '60130' '60304' '60305' '60106' '60203' '60090']\n",
      "Unique values in column 'dropoff_zipcode' (#119): ['60612' '60614' '60613' '60657' '60607' '60647' '60606' '60625' '60634'\n",
      " '60641' '60630' '60618' '60642' '60645' '60201' '60610' '60616' '60611'\n",
      " '60202' '60626' '60660' '60666' '60654' '60639' '60644' '60651' '60130'\n",
      " '60148' '60093' '60091' '60045' '60203' '60076' '60208' '60640' '60615'\n",
      " '60608' '60605' '60652' '60619' '60659' '60620' '60629' '60714' '60018'\n",
      " '60077' '60068' '60637' '60632' '60409' '60501' '60402' '60638' '60603'\n",
      " '60131' '60521' '60523' '60624' '60706' '60008' '60609' '60653' '60649'\n",
      " '60646' '60631' '60126' '60804' '60601' '60622' '60661' '60707' '60160'\n",
      " '60026' '60089' '60628' '06061' '60803' '60459' '60085' '60477' '60636'\n",
      " '60621' '60176' '60546' '60513' '60162' '60453' '60062' '60602' '60643'\n",
      " '60171' '60120' '60192' '60623' '60302' '60604' '60457' '60712' '60656'\n",
      " '60004' '60007' '60155' '60301' '60617' '60069' '60056' '60181' '60123'\n",
      " '60053' '60558' '60025' '60044' '60043' '60827' '60525' '60304' '60633'\n",
      " '60305' '60534']\n"
     ]
    }
   ],
   "source": [
    "rides_df = pd.DataFrame(enriched_rides)\n",
    "print(rides_df.describe())\n",
    "\n",
    "# Compute summary statistics for each column, including handling None values\n",
    "stats = rides_df.describe(include='all')\n",
    "\n",
    "# Count None values per column\n",
    "null_count = rides_df.isnull().sum()\n",
    "\n",
    "# Display the statistics and None count\n",
    "print(stats)\n",
    "print(\"\\nCount of None values per column:\\n\", null_count)\n",
    "\n",
    "# Additional information on string handling\n",
    "print(\"\\nAdditional Info:\")\n",
    "for column in rides_df.columns:\n",
    "    if rides_df[column].dtype == 'object':  # Handling for strings and mixed types\n",
    "        unique_strings = rides_df[column].dropna().unique()\n",
    "        print(f\"Unique values in column '{column}' (#{len(unique_strings)}): {unique_strings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef0f3196-b70b-4c39-a062-71676c724778",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"Uber Rides.csv\", 'w') as file:\n",
    "    dw = csv.DictWriter(file, fieldnames=enriched_rides[0].keys())\n",
    "    dw.writeheader()\n",
    "    dw.writerows(enriched_rides)\n",
    "\n",
    "with open(f\"Uber All Ride Data.csv\", 'w') as file:\n",
    "    dw = csv.DictWriter(file, fieldnames=cleaned_rides[0].keys())\n",
    "    dw.writeheader()\n",
    "    dw.writerows(cleaned_rides)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
